"""
ğŸ¨ æ•°æ®ç‚¼é‡‘å·¥åŠ - Streamlit Webç•Œé¢
æç®€ä¼˜é›…çš„æŠ–éŸ³ç”µå•†æ•°æ®å¤„ç†ç•Œé¢

ä½œè€…: ç•Œé¢è®¾è®¡å¸ˆ
è®¾è®¡ç†å¿µ: ç”¨æˆ·ä¸éœ€è¦çŸ¥é“ä»€ä¹ˆæ˜¯Polarså’ŒDuckDBï¼Œä»–ä»¬åªéœ€è¦ä¸€ä¸ªä¸Šä¼ æŒ‰é’®å’Œä¸€ä¸ªä¸‹è½½æŒ‰é’®
"""

import streamlit as st
import polars as pl
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
import sys
import tempfile
import time
from datetime import datetime
import io
import traceback
import os
import zipfile

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from core.etl_douyin import process_douyin_export, get_data_quality_report

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®ç‚¼é‡‘å·¥åŠ",
    page_icon="ğŸ—ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

def init_page_style():
    """åˆå§‹åŒ–é¡µé¢æ ·å¼"""
    st.markdown("""
    <style>
    /* ä¸»é¢˜è‰²å½© */
    :root {
        --primary-color: #FF6B6B;
        --secondary-color: #4ECDC4;
        --accent-color: #45B7D1;
        --success-color: #96CEB4;
        --warning-color: #FFEAA7;
        --error-color: #DDA0DD;
    }
    
    /* éšè—é»˜è®¤èœå• */
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    
    /* è‡ªå®šä¹‰æ ‡é¢˜æ ·å¼ */
    .main-title {
        font-size: 3rem;
        font-weight: 700;
        background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-align: center;
        margin-bottom: 1rem;
    }
    
    .subtitle {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
        font-style: italic;
    }
    
    /* å¡ç‰‡æ ·å¼ */
    .upload-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        color: white;
    }
    
    .result-card {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        padding: 2rem;
        border-radius: 15px;
        margin: 1rem 0;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
        color: white;
    }
    
    .feature-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 4px solid var(--primary-color);
        margin: 0.5rem 0;
        box-shadow: 0 2px 10px rgba(0,0,0,0.1);
    }
    
    /* è¿›åº¦æ¡æ ·å¼ */
    .stProgress > div > div > div > div {
        background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
    }
    
    /* æŒ‰é’®æ ·å¼ */
    .stDownloadButton > button {
        background: linear-gradient(45deg, #4ECDC4, #45B7D1);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: bold;
        transition: all 0.3s ease;
    }
    
    .stDownloadButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    </style>
    """, unsafe_allow_html=True)

def render_header():
    """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
    st.markdown('<h1 class="main-title">ğŸ—ï¸ æ•°æ®ç‚¼é‡‘å·¥åŠ</h1>', unsafe_allow_html=True)
    st.markdown('<p class="subtitle">"å°†åŸå§‹æ•°æ®ç‚¼æˆçº¯å‡€çš„æ•°æ®é»„é‡‘"</p>', unsafe_allow_html=True)
    
    # åŠŸèƒ½ä»‹ç»å¡ç‰‡
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="feature-card">
            <h4>ğŸš€ æ™ºèƒ½è§£æ</h4>
            <p>è‡ªåŠ¨è¯†åˆ«è‰å¦ˆå¦ˆå¤šè¡¨CSVç»“æ„</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="feature-card">
            <h4>ğŸ”§ æ¨¡ç³Šå¤„ç†</h4>
            <p>å°†"7.5w~10w"è½¬æ¢ä¸ºç²¾ç¡®æ•°å€¼</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="feature-card">
            <h4>âš¡ æé€Ÿæ€§èƒ½</h4>
            <p>åŸºäºPolarsçš„æè‡´æ€§èƒ½ä¼˜åŒ–</p>
        </div>
        """, unsafe_allow_html=True)

def render_file_upload():
    """æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ - æ”¯æŒæ‰¹é‡ä¸Šä¼ """
    st.markdown("""
    <div class="upload-card">
        <h3>ğŸ“ ä¸Šä¼ æ‚¨çš„æ•°æ®æ–‡ä»¶</h3>
        <p>æ”¯æŒè‰å¦ˆå¦ˆå¯¼å‡ºçš„CSV/Excelæ–‡ä»¶ï¼Œå¯æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶</p>
    </div>
    """, unsafe_allow_html=True)
    
    # é€‰æ‹©ä¸Šä¼ æ¨¡å¼
    upload_mode = st.radio(
        "é€‰æ‹©ä¸Šä¼ æ¨¡å¼",
        ["å•æ–‡ä»¶ä¸Šä¼ ", "æ‰¹é‡ä¸Šä¼ "],
        horizontal=True,
        help="å•æ–‡ä»¶ï¼šå¤„ç†ä¸€ä¸ªæ–‡ä»¶ï¼›æ‰¹é‡ï¼šåŒæ—¶å¤„ç†å¤šä¸ªæ–‡ä»¶å¹¶åˆå¹¶ç»“æœ"
    )
    
    if upload_mode == "å•æ–‡ä»¶ä¸Šä¼ ":
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            help="ä¸Šä¼ è‰å¦ˆå¦ˆå¯¼å‡ºçš„æ•°æ®æ–‡ä»¶ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«å¹¶å¤„ç†å¤šè¡¨æ•°æ®",
            label_visibility="collapsed"
        )
        return [uploaded_files] if uploaded_files else []
    else:
        uploaded_files = st.file_uploader(
            "é€‰æ‹©å¤šä¸ªæ–‡ä»¶",
            type=['csv', 'xlsx', 'xls'],
            accept_multiple_files=True,
            help="ä¸€æ¬¡ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ï¼Œç³»ç»Ÿå°†æ‰¹é‡å¤„ç†å¹¶åˆå¹¶ç»“æœ",
            label_visibility="collapsed"
        )
        return uploaded_files if uploaded_files else []

def render_processing_animation():
    """æ¸²æŸ“å¤„ç†åŠ¨ç”»"""
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    steps = [
        "ğŸ” æ™ºèƒ½è¯†åˆ«è¡¨æ ¼ç»“æ„...",
        "ğŸ“Š è§£æå¤šè¡¨æ•°æ®...",
        "ğŸ§¹ æ¸…æ´—æ¨¡ç³Šæ•°å€¼èŒƒå›´...", 
        "âš™ï¸ æ ‡å‡†åŒ–æ•°æ®æ ¼å¼...",
        "ğŸ¯ ç”Ÿæˆæ•°æ®è´¨é‡æŠ¥å‘Š...",
        "âœ¨ æ•°æ®ç‚¼é‡‘å®Œæˆï¼"
    ]
    
    for i, step in enumerate(steps):
        progress_bar.progress((i + 1) / len(steps))
        status_text.text(step)
        time.sleep(0.5)
    
    status_text.text("ğŸ‰ å¤„ç†å®Œæˆï¼")
    return progress_bar, status_text

def render_data_overview(df: pl.DataFrame, quality_report: dict):
    """æ¸²æŸ“æ•°æ®æ¦‚è§ˆ"""
    st.markdown("""
    <div class="result-card">
        <h3>ğŸ“Š æ•°æ®å¤„ç†ç»“æœ</h3>
        <p>æ‚¨çš„æ•°æ®å·²æˆåŠŸç‚¼åˆ¶å®Œæˆï¼Œå¯ä»¥å¼€å§‹åˆ†æäº†ï¼</p>
    </div>
    """, unsafe_allow_html=True)
    
    # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»è¡Œæ•°", f"{quality_report['total_rows']:,}", delta=None)
    
    with col2:
        st.metric("æ€»åˆ—æ•°", f"{quality_report['total_columns']}", delta=None)
    
    with col3:
        # è®¡ç®—æ•°å€¼åˆ—æ•°é‡
        numeric_cols = len([col for col in df.columns if df[col].dtype in [pl.Float64, pl.Int64]])
        st.metric("æ•°å€¼åˆ—", f"{numeric_cols}", delta=None)
    
    with col4:
        # è®¡ç®—ç”Ÿæˆçš„èŒƒå›´åˆ—æ•°é‡
        range_cols = len([col for col in df.columns if '_avg' in col])
        st.metric("ç”ŸæˆèŒƒå›´åˆ—", f"{range_cols}", delta=None)

def render_data_quality_chart(quality_report: dict):
    """æ¸²æŸ“æ•°æ®è´¨é‡å›¾è¡¨"""
    st.subheader("ğŸ“ˆ æ•°æ®è´¨é‡åˆ†æ")
    
    # ç©ºå€¼åˆ†æ
    null_data = quality_report['null_counts']
    if any(count > 0 for count in null_data.values()):
        null_df = pd.DataFrame([
            {"åˆ—å": col, "ç©ºå€¼æ•°é‡": count, "ç©ºå€¼æ¯”ä¾‹": count / quality_report['total_rows']}
            for col, count in null_data.items()
            if count > 0
        ])
        
        fig = px.bar(
            null_df, 
            x="åˆ—å", 
            y="ç©ºå€¼æ•°é‡",
            title="ç©ºå€¼åˆ†å¸ƒæƒ…å†µ",
            color="ç©ºå€¼æ¯”ä¾‹",
            color_continuous_scale="Reds"
        )
        st.plotly_chart(fig, use_container_width=True)
    else:
        st.success("ğŸ‰ æ•°æ®è´¨é‡ä¼˜ç§€ï¼æ²¡æœ‰å‘ç°ç©ºå€¼ã€‚")
    
    # æ•°æ®ç±»å‹åˆ†æ
    type_data = quality_report['data_types']
    type_counts = {}
    for dtype in type_data.values():
        type_counts[dtype] = type_counts.get(dtype, 0) + 1
    
    fig_pie = px.pie(
        values=list(type_counts.values()),
        names=list(type_counts.keys()),
        title="æ•°æ®ç±»å‹åˆ†å¸ƒ"
    )
    st.plotly_chart(fig_pie, use_container_width=True)

def render_data_preview(df: pl.DataFrame):
    """æ¸²æŸ“æ•°æ®é¢„è§ˆ"""
    st.subheader("ğŸ‘€ æ•°æ®é¢„è§ˆ")
    
    # è½¬æ¢ä¸ºpandasä»¥ä¾¿åœ¨streamlitä¸­æ˜¾ç¤º
    df_pandas = df.to_pandas()
    
    # æ˜¾ç¤ºå‰å‡ è¡Œ
    st.write("**å‰5è¡Œæ•°æ®:**")
    st.dataframe(df_pandas.head(), use_container_width=True)
    
    # å¦‚æœæœ‰èŒƒå›´åˆ—ï¼Œå±•ç¤ºè½¬æ¢æ•ˆæœ
    range_columns = [col for col in df.columns if col.endswith('_avg')]
    if range_columns:
        st.write("**æ¨¡ç³Šæ•°å€¼èŒƒå›´å¤„ç†æ•ˆæœ:**")
        
        # æ‰¾åˆ°åŸå§‹åˆ—å’Œå¯¹åº”çš„èŒƒå›´åˆ—
        for avg_col in range_columns[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
            base_col = avg_col.replace('_avg', '')
            if base_col in df.columns:
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.write(f"**åŸå§‹**: {base_col}")
                    st.write(df_pandas[base_col].iloc[0] if len(df_pandas) > 0 else "æ— æ•°æ®")
                with col2:
                    st.write(f"**æœ€å°å€¼**: {avg_col.replace('_avg', '_min')}")
                    min_col = avg_col.replace('_avg', '_min')
                    if min_col in df.columns:
                        st.write(f"{df_pandas[min_col].iloc[0]:,.0f}" if len(df_pandas) > 0 and pd.notna(df_pandas[min_col].iloc[0]) else "N/A")
                with col3:
                    st.write(f"**æœ€å¤§å€¼**: {avg_col.replace('_avg', '_max')}")
                    max_col = avg_col.replace('_avg', '_max')
                    if max_col in df.columns:
                        st.write(f"{df_pandas[max_col].iloc[0]:,.0f}" if len(df_pandas) > 0 and pd.notna(df_pandas[max_col].iloc[0]) else "N/A")
                with col4:
                    st.write(f"**å¹³å‡å€¼**: {avg_col}")
                    st.write(f"{df_pandas[avg_col].iloc[0]:,.0f}" if len(df_pandas) > 0 and pd.notna(df_pandas[avg_col].iloc[0]) else "N/A")
                st.divider()

def create_download_file(df: pl.DataFrame, format="csv") -> bytes:
    """åˆ›å»ºä¸‹è½½æ–‡ä»¶ - ä¿®å¤ç‰ˆï¼šé»˜è®¤CSVæ ¼å¼ï¼Œå…¼å®¹Excel"""
    if format.lower() == "csv":
        # ğŸ”§ æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨utf-8-sigç¼–ç ï¼Œç¡®ä¿Excelå…¼å®¹æ€§
        csv_string = df.write_csv()
        csv_bytes_with_bom = csv_string.encode('utf-8-sig')
        return csv_bytes_with_bom
    else:
        # Parquetæ ¼å¼ï¼ˆå¯é€‰ï¼‰
        buffer = io.BytesIO()
        df.write_parquet(buffer)
        buffer.seek(0)
        return buffer.getvalue()

def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–æ ·å¼
    init_page_style()
    
    # æ¸²æŸ“å¤´éƒ¨
    render_header()
    
    # ä¾§è¾¹æ ä¿¡æ¯
    with st.sidebar:
        st.markdown("### ğŸ¯ ä½¿ç”¨æŒ‡å—")
        st.markdown("""
        1. **é€‰æ‹©æ¨¡å¼**: å•æ–‡ä»¶æˆ–æ‰¹é‡ä¸Šä¼ 
        2. **ä¸Šä¼ æ–‡ä»¶**: æ”¯æŒCSV/Excelæ ¼å¼
        3. **è‡ªåŠ¨å¤„ç†**: ç³»ç»Ÿæ™ºèƒ½è¯†åˆ«å’Œæ¸…æ´—
        4. **ä¸‹è½½ç»“æœ**: CSVæ ¼å¼(å…¼å®¹Excel)
        
        ---
        
        ### ğŸ”§ æŠ€æœ¯ç‰¹æ€§
        - ğŸš€ **æ™ºèƒ½å¼•æ“**: pandas+polarsæ··åˆ
        - ğŸ“ **æ‰¹é‡å¤„ç†**: æ”¯æŒå¤šæ–‡ä»¶åŒæ—¶å¤„ç†
        - ğŸ§  **æ™ºèƒ½è§£æ**: å¤šè¡¨è‡ªåŠ¨è¯†åˆ«
        - ğŸ” **æ¨¡ç³Šå¤„ç†**: èŒƒå›´æ•°å€¼ç²¾ç¡®åŒ–
        - ğŸ“Š **è´¨é‡æŠ¥å‘Š**: å®Œæ•´æ•°æ®åˆ†æ
        - ğŸŒ **Excelå…¼å®¹**: UTF-8-BOMç¼–ç 
        
        ---
        
        ### ğŸ†• æœ€æ–°æ›´æ–°
        - âœ… **CSVé»˜è®¤å¯¼å‡º**: å…¼å®¹Excel
        - âœ… **æ‰¹é‡ä¸Šä¼ **: å¤šæ–‡ä»¶å¤„ç†
        - âœ… **æ™ºèƒ½åˆå¹¶**: è‡ªåŠ¨æ•°æ®åˆå¹¶
        - âœ… **è¿›åº¦æ˜¾ç¤º**: å®æ—¶å¤„ç†çŠ¶æ€
        
        ---
        
        ### ğŸ“ æŠ€æœ¯æ”¯æŒ
        å¦‚éœ€å¸®åŠ©ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿï¼š
        - ğŸ—ï¸ ç®¡é“æ¶æ„å¸ˆ
        - ğŸ¨ ç•Œé¢è®¾è®¡å¸ˆ
        """)
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    uploaded_files = render_file_upload()
    
    if uploaded_files:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        if len(uploaded_files) == 1:
            st.success(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {uploaded_files[0].name}")
            st.info(f"ğŸ“ æ–‡ä»¶å¤§å°: {len(uploaded_files[0].getvalue()) / 1024:.1f} KB")
        else:
            st.success(f"âœ… æ‰¹é‡ä¸Šä¼ æˆåŠŸ: {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            total_size = sum(len(f.getvalue()) for f in uploaded_files) / 1024
            st.info(f"ğŸ“ æ€»æ–‡ä»¶å¤§å°: {total_size:.1f} KB")
            
            # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨
            with st.expander("ğŸ“‹ æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨"):
                for i, f in enumerate(uploaded_files, 1):
                    st.write(f"{i}. {f.name} ({len(f.getvalue()) / 1024:.1f} KB)")
        
        # å¤„ç†æŒ‰é’® - ä¿®å¤ç‰ˆæœ¬ï¼šåˆ†è€Œæ²»ä¹‹ï¼Œä¸åˆå¹¶æ•°æ®
        if st.button("ğŸš€ å¼€å§‹æ•°æ®ç‚¼é‡‘", type="primary", use_container_width=True):
            
            st.info("ğŸ”§ æ•°æ®ç‚¼é‡‘å¼€å§‹ï¼æ­£åœ¨å‡†å¤‡å¤„ç†ç¯å¢ƒ...")
            
            # ç‹¬ç«‹å¤„ç†æ¯ä¸ªæ–‡ä»¶ï¼Œä¸å†åˆå¹¶
            for index, up_file in enumerate(uploaded_files):
                st.markdown(f"---\n### æ­£åœ¨å¤„ç†æ–‡ä»¶ {index + 1}: `{up_file.name}`")
                
                try:
                    # 1. ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(up_file.name)[1]) as tmp_file:
                        tmp_file.write(up_file.getvalue())
                        tmp_file_path = tmp_file.name
                    
                    # 2. è°ƒç”¨æ ¸å¿ƒå¼•æ“å¤„ç†
                    cleaned_df = process_douyin_export(tmp_file_path)
                    
                    if cleaned_df is None:
                        st.error(f"âŒ æ— æ³•è§£ææ–‡ä»¶ `{up_file.name}` ä¸­çš„æœ‰æ•ˆæ•°æ®")
                        continue
                    
                    # 3. è·å–åŸå§‹æ•°æ®ç”¨äºå¯¹æ¯”ï¼ˆé‡æ–°è¯»å–ä»¥æ˜¾ç¤ºåŸå§‹çŠ¶æ€ï¼‰
                    try:
                        if up_file.name.endswith('.csv'):
                            original_df = pl.read_csv(tmp_file_path, encoding='utf-8-sig', separator='\t')
                        else:
                            original_df = pl.read_excel(tmp_file_path)
                        original_df = original_df.head(5)  # åªæ˜¾ç¤ºå‰5è¡Œ
                    except:
                        original_df = cleaned_df.head(5)  # å¦‚æœè¯»å–å¤±è´¥ï¼Œä½¿ç”¨æ¸…æ´—åçš„æ•°æ®
                    
                    # 4. ç«‹å³å±•ç¤ºå¤„ç†ç»“æœ
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.write("#### ğŸ“‹ åŸå§‹æ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
                        st.dataframe(original_df.to_pandas(), use_container_width=True)
                    
                    with col2:
                        st.write("#### âœ¨ æ¸…æ´—åæ•°æ®é¢„è§ˆ (å‰5è¡Œ)")
                        st.dataframe(cleaned_df.head(5).to_pandas(), use_container_width=True)
                    
                    # 5. æ•°æ®ç»Ÿè®¡ä¿¡æ¯
                    st.write("**å¤„ç†ç»Ÿè®¡:**")
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ€»è¡Œæ•°", f"{len(cleaned_df):,}")
                    with col2:
                        st.metric("æ€»åˆ—æ•°", len(cleaned_df.columns))
                    with col3:
                        range_cols = [col for col in cleaned_df.columns if col.endswith('_avg')]
                        st.metric("èŒƒå›´åˆ—", len(range_cols))
                    with col4:
                        st.metric("æ–‡ä»¶å¤§å°", f"{len(up_file.getvalue()) / 1024:.1f} KB")
                    
                    # 6. æä¾›ç‹¬ç«‹çš„ä¸‹è½½æŒ‰é’®
                    csv_string = cleaned_df.write_csv()
                    csv_bytes_with_bom = csv_string.encode('utf-8-sig')
                    
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è½½æ¸…æ´—åçš„æ•°æ®: {up_file.name}",
                        data=csv_bytes_with_bom,
                        file_name=f"cleaned_{up_file.name}",
                        mime="text/csv",
                        key=f"download-btn-{index}",  # æ¯ä¸ªæŒ‰é’®å¿…é¡»æœ‰å”¯ä¸€çš„key
                        help="CSVæ ¼å¼ï¼Œå·²ä½¿ç”¨UTF-8-BOMç¼–ç ï¼Œå¯ç›´æ¥åœ¨Excelä¸­æ‰“å¼€"
                    )
                    
                    st.success(f"âœ… `{up_file.name}` å¤„ç†å®Œæˆï¼")
                    
                except Exception as e:
                    st.error(f"âŒ å¤„ç† `{up_file.name}` æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    # æ‰“å°è¯¦ç»†çš„Tracebackï¼Œæ–¹ä¾¿è°ƒè¯•
                    st.code(traceback.format_exc())
                    
                finally:
                    # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
                    if 'tmp_file_path' in locals() and os.path.exists(tmp_file_path):
                        os.remove(tmp_file_path)
            
            # å¤„ç†å®Œæˆåçš„æ€»ç»“
            st.markdown("---")
            st.header("ğŸ‰ å¤„ç†å®Œæˆï¼")
            st.info("æ‰€æœ‰æ–‡ä»¶å·²ç‹¬ç«‹å¤„ç†å®Œæˆï¼Œè¯·åœ¨ä¸Šæ–¹æŸ¥çœ‹æ¯ä¸ªæ–‡ä»¶çš„å¤„ç†ç»“æœå¹¶ä¸‹è½½ã€‚")


def process_single_file(uploaded_file) -> pl.DataFrame:
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    try:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        file_extension = os.path.splitext(uploaded_file.name)[1]
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # æ˜¾ç¤ºå¤„ç†åŠ¨ç”»
        with st.spinner("æ­£åœ¨ç‚¼åˆ¶æ‚¨çš„æ•°æ®..."):
            progress_bar, status_text = render_processing_animation()
        
        try:
            # è°ƒç”¨æ ¸å¿ƒå¤„ç†å‡½æ•°
            result_df = process_douyin_export(tmp_file_path)
            return result_df
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.remove(tmp_file_path)
    
    except Exception as e:
        st.error(f"âŒ å¤„ç†æ–‡ä»¶ {uploaded_file.name} å¤±è´¥: {str(e)}")
        st.exception(e)
        return None


def process_multiple_files(uploaded_files) -> pl.DataFrame:
    """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
    processed_dfs = []
    failed_files = []
    
    # åˆ›å»ºè¿›åº¦æ¡
    progress_bar = st.progress(0)
    status_container = st.container()
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            with status_container:
                st.write(f"ğŸ”„ æ­£åœ¨å¤„ç†æ–‡ä»¶ {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_bar.progress((i + 1) / len(uploaded_files))
            
            # ä¿å­˜æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
            file_extension = os.path.splitext(uploaded_file.name)[1]
            with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_file_path = tmp_file.name
            
            try:
                # å¤„ç†æ–‡ä»¶
                result_df = process_douyin_export(tmp_file_path)
                
                # æ·»åŠ æ–‡ä»¶æ¥æºåˆ—
                result_df = result_df.with_columns([
                    pl.lit(uploaded_file.name).alias("æ–‡ä»¶æ¥æº")
                ])
                
                processed_dfs.append(result_df)
                
                with status_container:
                    st.write(f"âœ… {uploaded_file.name} å¤„ç†å®Œæˆ: {len(result_df)} è¡Œæ•°æ®")
                
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                os.remove(tmp_file_path)
                
        except Exception as e:
            failed_files.append(uploaded_file.name)
            with status_container:
                st.write(f"âŒ {uploaded_file.name} å¤„ç†å¤±è´¥: {str(e)}")
    
    # åˆå¹¶æ‰€æœ‰å¤„ç†æˆåŠŸçš„DataFrame
    if processed_dfs:
        try:
            # ä½¿ç”¨Polarsçš„concatå‡½æ•°åˆå¹¶
            merged_df = pl.concat(processed_dfs, how="diagonal")
            
            success_count = len(processed_dfs)
            total_rows = len(merged_df)
            
            st.success(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸå¤„ç† {success_count}/{len(uploaded_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {total_rows} è¡Œæ•°æ®")
            
            if failed_files:
                st.warning(f"âš ï¸ ä»¥ä¸‹æ–‡ä»¶å¤„ç†å¤±è´¥: {', '.join(failed_files)}")
            
            return merged_df
            
        except Exception as e:
            st.error(f"âŒ åˆå¹¶æ•°æ®å¤±è´¥: {str(e)}")
            return None
    else:
        st.error("âŒ æ²¡æœ‰ä»»ä½•æ–‡ä»¶å¤„ç†æˆåŠŸ")
        return None
    
    # æ˜¾ç¤ºå¤„ç†ç»“æœ
    if 'processed_df' in st.session_state:
        df = st.session_state.processed_df
        quality_report = st.session_state.quality_report
        original_filenames = st.session_state.get('original_filenames', ['unknown_file'])
        
        # æ¸²æŸ“ç»“æœæ¦‚è§ˆ
        render_data_overview(df, quality_report)
        
        # ä¸‹è½½åŒºåŸŸ - æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„ã€æœ€ç»ˆæ­£ç¡®ç‰ˆæœ¬ã€‘
        st.subheader("ä¸‹è½½æ¸…æ´—åçš„æ•°æ®")

        # --- æ ¸å¿ƒä¿®å¤ç‚¹ ---
        # 1. è°ƒç”¨ Polars çš„ write_csv æ–¹æ³•ï¼Œå°† DataFrame è½¬æ¢ä¸º CSV æ ¼å¼çš„å­—ç¬¦ä¸²ã€‚
        csv_string = df.write_csv()

        # 2. å°†è¯¥å­—ç¬¦ä¸²ç¼–ç ä¸º 'utf-8-sig'ã€‚
        #    è¿™ä¸ª'sig' (Signature, å³BOM) æ˜¯å…³é”®ï¼Œå®ƒä¼šå‘Šè¯‰ Excel ç­‰è½¯ä»¶
        #    "è¿™æ˜¯ä¸€ä¸ªUTF-8ç¼–ç çš„æ–‡ä»¶"ï¼Œä»è€Œæ­£ç¡®æ˜¾ç¤ºä¸­æ–‡å­—ç¬¦ã€‚
        csv_bytes_with_bom = csv_string.encode('utf-8-sig')

        # 3. åˆ›å»ºä¸‹è½½æŒ‰é’®ï¼Œå¹¶æä¾›æ­£ç¡®çš„æ•°æ®å’Œ MIME ç±»å‹ã€‚
        st.download_button(
            label="â¬‡ï¸ ä¸‹è½½æ¸…æ´—ç»“æœ (å…¼å®¹Excelçš„CSVæ ¼å¼)",
            data=csv_bytes_with_bom,
            file_name=f"cleaned_data_{time.strftime('%Y%m%d_%H%M%S')}.csv", # åŠ ä¸Šæ—¶é—´æˆ³é¿å…é‡å
            mime="text/csv"
        )
        
        # å¯é€‰çš„é¢å¤–ä¸‹è½½æ ¼å¼
        with st.expander("ğŸ”§ å…¶ä»–æ ¼å¼ä¸‹è½½ (å¯é€‰)"):
            col1, col2 = st.columns(2)
            
            with col1:
                # Parquetæ ¼å¼ï¼ˆé«˜æ€§èƒ½ï¼‰
                parquet_data = create_download_file(df, format="parquet")
                parquet_filename = f"cleaned_data_{time.strftime('%Y%m%d_%H%M%S')}.parquet"
                
                st.download_button(
                    label="ğŸ“Š ä¸‹è½½Parquetæ ¼å¼ (é«˜æ€§èƒ½)",
                    data=parquet_data,
                    file_name=parquet_filename,
                    mime="application/octet-stream",
                    help="Parquetæ ¼å¼ï¼Œä½“ç§¯æ›´å°ï¼Œå¤„ç†é€Ÿåº¦æ›´å¿«ï¼Œé€‚åˆæ•°æ®åˆ†æ"
                )
            
            with col2:
                # Excelæ ¼å¼ï¼ˆå¦‚æœéœ€è¦ï¼‰
                st.info("ğŸ’¡ ä¸»è¦ä¸‹è½½æŒ‰é’®å·²ä½¿ç”¨CSVæ ¼å¼ï¼Œå¯ç›´æ¥åœ¨Excelä¸­æ‰“å¼€")
        
        # è¯¦ç»†åˆ†æ
        st.divider()
        
        # æ•°æ®è´¨é‡å›¾è¡¨
        render_data_quality_chart(quality_report)
        
        # æ•°æ®é¢„è§ˆ
        render_data_preview(df)
        
        # æŠ€æœ¯ç»†èŠ‚ï¼ˆå¯æŠ˜å ï¼‰
        with st.expander("ğŸ” æŸ¥çœ‹æŠ€æœ¯ç»†èŠ‚"):
            st.write("**å¤„ç†ç»Ÿè®¡ä¿¡æ¯:**")
            col1, col2 = st.columns(2)
            
            with col1:
                st.json({
                    "åŸå§‹æ–‡ä»¶": ", ".join(original_filenames) if len(original_filenames) <= 3 else f"{', '.join(original_filenames[:3])} ç­‰{len(original_filenames)}ä¸ªæ–‡ä»¶",
                    "å¤„ç†æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "æ•°æ®ç»´åº¦": f"{quality_report['total_rows']} è¡Œ Ã— {quality_report['total_columns']} åˆ—",
                    "å¤„ç†å¼•æ“": "pandas+polars æ··åˆå¼•æ“",
                    "æ–‡ä»¶æ•°é‡": len(original_filenames)
                })
            
            with col2:
                st.write("**åˆ—ååˆ—è¡¨:**")
                for i, col in enumerate(df.columns, 1):
                    st.write(f"{i}. {col}")

if __name__ == "__main__":
    main()