# æŠ€æœ¯å®ç°ç»†èŠ‚æ–‡æ¡£

## æ ¸å¿ƒæŠ€æœ¯æ¶æ„

### 1. æ•°æ®å¤„ç†å¼•æ“ (ETL Core)

#### 1.1 æ–‡ä»¶è§£ææ¨¡å—
**æ–‡ä»¶**: `app/core/etl_douyin.py`

```python
def parse_messy_file(file_path: Union[str, Path]) -> Dict[str, pl.DataFrame]:
    """
    æ™ºèƒ½è§£ææ··ä¹±çš„æ–‡ä»¶ - æ ¸å¿ƒç®—æ³•
    
    æŠ€æœ¯è¦ç‚¹:
    1. è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»å‹ (CSV/Excel)
    2. æ™ºèƒ½ç¼–ç è¯†åˆ« (UTF-8-SIG, GBK, GB2312)
    3. å¤šè¡¨ç»“æ„è‡ªåŠ¨åˆ†ç¦»
    4. è¡¨å¤´å…³é”®è¯åŒ¹é…ç®—æ³•
    """
```

**å…³é”®ç®—æ³•**:
- **ç¼–ç æ£€æµ‹**: ä½¿ç”¨chardet + å€™é€‰ç¼–ç åˆ—è¡¨
- **åˆ†éš”ç¬¦è¯†åˆ«**: ç»Ÿè®¡åˆ†æåˆ¶è¡¨ç¬¦ã€é€—å·ç­‰
- **è¡¨å¤´è¯†åˆ«**: 20+å…³é”®è¯åŒ¹é… + éç©ºå•å…ƒæ ¼å æ¯”
- **è¡¨æ ¼åˆ†ç¦»**: åŸºäºè¡¨å¤´ä½ç½®çš„åŒºé—´åˆ‡åˆ†

#### 1.2 æ¨¡ç³Šæ•°å€¼è§£æå¼•æ“
```python
def parse_fuzzy_numeric_range(series: pl.Series) -> Dict[str, pl.Series]:
    """
    æ¨¡ç³Šæ•°å€¼èŒƒå›´è§£æ - æ ¸å¿ƒç®—æ³•
    
    æ”¯æŒæ ¼å¼:
    - "7.5w~10w" â†’ min:75000, max:100000, avg:87500
    - "20.00%" â†’ 0.2
    - "346.95ä¸‡" â†’ 3469500
    """
```

**è§£æè§„åˆ™**:
```python
UNIT_MAP = {
    "w": 10_000,     # ä¸‡
    "ä¸‡": 10_000,
    "k": 1_000,      # åƒ
    "åƒ": 1_000
}

# æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
RANGE_PATTERN = r"([0-9.]+)\s*([wä¸‡kåƒ%]?)\s*[~ï½-]\s*([0-9.]+)\s*([wä¸‡kåƒ%]?)"
SINGLE_PATTERN = r"([0-9.]+)\s*([wä¸‡kåƒ%]?)"
```

#### 1.3 æ•°æ®æ¸…æ´—æ ¸å¿ƒé€»è¾‘

**Version 1.0 (å·²åºŸå¼ƒ)**:
```python
# æ—§ç‰ˆæœ¬ - åˆ›å»ºå¤šåˆ—
def clean_common_fields_old(df: pl.DataFrame) -> pl.DataFrame:
    for field in range_fields:
        range_data = parse_fuzzy_numeric_range(df[field])
        df = df.with_columns([
            range_data['min'].alias(f'{field}_min'),
            range_data['max'].alias(f'{field}_max'),
            range_data['avg'].alias(f'{field}_avg')
        ])
        df = df.drop(field)  # åˆ é™¤åŸå§‹åˆ—
    return df
```

**Version 2.0 (å½“å‰ç‰ˆæœ¬)**:
```python
# æ–°ç‰ˆæœ¬ - ä¿ç•™åŸå§‹æ•°æ® + _filteråˆ—
def clean_common_fields(df: pl.DataFrame) -> pl.DataFrame:
    cleaned_df = df.clone()  # ä¿ç•™æ‰€æœ‰åŸå§‹åˆ—
    
    for field in range_fields:
        if field in df.columns:
            range_data = parse_fuzzy_numeric_range(df[field])
            # åªåˆ›å»º_filteråˆ—å­˜å‚¨ä¸‹é™å€¼
            cleaned_df = cleaned_df.with_columns([
                range_data['min'].alias(f'{field}_filter')
            ])
    
    return cleaned_df  # åŸå§‹åˆ— + _filteråˆ—
```

### 2. Webç•Œé¢æ¶æ„ (Streamlit)

#### 2.1 ç•Œé¢è®¾è®¡ç³»ç»Ÿ
**æ–‡ä»¶**: `app/ui/streamlit_app.py`

**è®¾è®¡ç†å¿µ**: æç®€ç¾å­¦ + æ¸å˜è‰²å½©
```css
/* ä¸»é¢˜è‰²å½©ç³»ç»Ÿ */
:root {
    --primary-color: #FF6B6B;     /* ä¸»è‰²è°ƒ */
    --secondary-color: #4ECDC4;   /* è¾…åŠ©è‰² */
    --accent-color: #45B7D1;      /* å¼ºè°ƒè‰² */
    --success-color: #96CEB4;     /* æˆåŠŸè‰² */
    --warning-color: #FFEAA7;     /* è­¦å‘Šè‰² */
    --error-color: #DDA0DD;       /* é”™è¯¯è‰² */
}

/* æ¸å˜å¡ç‰‡ */
.upload-card {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border-radius: 15px;
    box-shadow: 0 8px 32px rgba(0,0,0,0.1);
}
```

#### 2.2 çŠ¶æ€ç®¡ç†ç³»ç»Ÿ
```python
# Session State ç®¡ç†
if 'processed_files' not in st.session_state:
    st.session_state.processed_files = []

if 'filtered_results' not in st.session_state:
    st.session_state.filtered_results = None

# æ–‡ä»¶å¤„ç†çŠ¶æ€è·Ÿè¸ª
st.session_state.current_file = uploaded_file.name
st.session_state.original_df = df_original
st.session_state.processed_df = process_dataframe(df_original)
```

#### 2.3 æ•°æ®ç­›é€‰UIå®ç°
```python
# åŠ¨æ€ç”Ÿæˆç­›é€‰æ§ä»¶
def render_filter_sidebar():
    filter_columns = [col.replace('_filter', '') 
                     for col in df.columns 
                     if col.endswith('_filter')]
    
    filters = {}
    for col in filter_columns:
        filter_col = f"{col}_filter"
        min_val = float(df[filter_col].min())
        max_val = float(df[filter_col].max())
        
        # æ»‘å—æ§ä»¶
        selected_range = st.slider(
            f"{col}",
            min_val,
            max_val,
            (min_val, max_val),
            key=f"filter_{col}"
        )
        filters[filter_col] = selected_range
    
    return filters
```

### 3. æ•°æ®æµè½¬æ¶æ„

#### 3.1 å®Œæ•´æ•°æ®æµ
```
ç”¨æˆ·ä¸Šä¼ æ–‡ä»¶
    â†“
æ™ºèƒ½ç¼–ç æ£€æµ‹ (detect_encoding)
    â†“
æ–‡ä»¶æ ¼å¼è¯†åˆ« (detect_file_type)
    â†“
å¤šè¡¨ç»“æ„è§£æ (parse_messy_file)
    â†“
è¡¨å¤´è¯†åˆ«ç®—æ³• (_detect_tables_in_sheet)
    â†“
æ•°æ®æ¸…æ´—å¤„ç† (clean_common_fields)
    â†“
æ·»åŠ _filteråˆ— (parse_fuzzy_numeric_range)
    â†“
UIå±•ç¤ºåŸå§‹æ•°æ® (ç§»é™¤_filteråˆ—)
    â†“
ç”¨æˆ·ç­›é€‰æ“ä½œ (åŸºäº_filteråˆ—)
    â†“
ç­›é€‰ç»“æœå±•ç¤º (ç§»é™¤_filteråˆ—)
    â†“
æ•°æ®ä¸‹è½½å¯¼å‡º (ç§»é™¤_filteråˆ—)
```

#### 3.2 é”™è¯¯å¤„ç†æœºåˆ¶
```python
# å¤šçº§é”™è¯¯å¤„ç†
try:
    # 1. æ–‡ä»¶è¯»å–é”™è¯¯
    df = pl.read_excel(file_path)
except Exception as e:
    logger.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    try:
        # 2. é™çº§åˆ°CSVå¤„ç†
        df = pl.read_csv(file_path, encoding='utf-8-sig')
    except Exception as e2:
        logger.error(f"CSVè¯»å–ä¹Ÿå¤±è´¥: {e2}")
        return None

# 3. æ•°æ®éªŒè¯
if df.is_empty():
    raise ValueError("æ•°æ®ä¸ºç©º")

# 4. å…³é”®åˆ—æ£€æŸ¥
required_columns = ["å•†å“", "é”€é‡"]
missing_columns = [col for col in required_columns if col not in df.columns]
if missing_columns:
    logger.warning(f"ç¼ºå°‘å…³é”®åˆ—: {missing_columns}")
```

### 4. æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

#### 4.1 Polarsä¼˜åŒ–ç­–ç•¥
```python
# æ‡’æƒ°æ‰§è¡Œ - æŸ¥è¯¢ä¼˜åŒ–
lazy_df = df.lazy()
result = lazy_df.filter(
    pl.col("é”€é‡_filter") > 10000
).select([
    pl.col("å•†å“"),
    pl.col("é”€é‡"),
    pl.col("é”€é‡_filter")
]).collect()

# é›¶æ‹·è´æ“ä½œ
cleaned_df = df.clone()  # å…±äº«å†…å­˜ï¼Œä¸å¤åˆ¶æ•°æ®

# æ‰¹é‡åˆ—æ“ä½œ
df = df.with_columns([
    pl.col("ä½£é‡‘æ¯”ä¾‹").str.replace("%", "").cast(pl.Float64).alias("ä½£é‡‘æ¯”ä¾‹_filter"),
    pl.col("é”€é‡").str.replace("w", "").cast(pl.Float64).mul(10000).alias("é”€é‡_filter")
])
```

#### 4.2 å†…å­˜ç®¡ç†
```python
# ä¸´æ—¶æ–‡ä»¶æ¸…ç†
try:
    with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name
    
    # å¤„ç†æ–‡ä»¶
    result = process_douyin_export(tmp_file_path)
    
finally:
    # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶è¢«åˆ é™¤
    if os.path.exists(tmp_file_path):
        os.remove(tmp_file_path)
```

#### 4.3 æ‰¹é‡å¤„ç†ä¼˜åŒ–
```python
# å¹¶è¡Œå¤„ç†å¤šæ–‡ä»¶
processed_files = []
with st.spinner("æ‰¹é‡å¤„ç†ä¸­..."):
    for idx, file in enumerate(uploaded_files):
        # è¿›åº¦æ˜¾ç¤º
        progress_bar.progress((idx + 1) / len(uploaded_files))
        
        # å¼‚æ­¥å¤„ç†
        result = process_file_async(file)
        processed_files.append(result)

# å†…å­˜å‹å¥½çš„ZIPåˆ›å»º
zip_buffer = io.BytesIO()
with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
    for file_info in processed_files:
        # ç§»é™¤_filteråˆ—åå†å‹ç¼©
        export_df = file_info['df'].drop([col for col in file_info['df'].columns if col.endswith('_filter')])
        csv_content = export_df.write_csv()
        zip_file.writestr(f"cleaned_{file_info['name']}", csv_content.encode('utf-8-sig'))
```

### 5. æµ‹è¯•æ¶æ„

#### 5.1 å•å…ƒæµ‹è¯•è®¾è®¡
```python
# test_etl_douyin.py
class TestETLDouyin:
    def test_parse_fuzzy_numeric_range(self):
        """æµ‹è¯•æ¨¡ç³Šæ•°å€¼è§£æ"""
        test_data = pl.Series(["7.5w~10w", "2.5w", "20%", "1000"])
        result = parse_fuzzy_numeric_range(test_data)
        
        assert result['min'][0] == 75000.0
        assert result['max'][0] == 100000.0
        assert result['avg'][0] == 87500.0
    
    def test_clean_common_fields_preserves_original(self):
        """æµ‹è¯•åŸå§‹æ•°æ®ä¿ç•™"""
        original_df = pl.DataFrame({
            "å•†å“": ["æµ‹è¯•å•†å“"],
            "é”€é‡": ["7.5w~10w"]
        })
        
        cleaned_df = clean_common_fields(original_df)
        
        # éªŒè¯åŸå§‹åˆ—ä¿ç•™
        assert "å•†å“" in cleaned_df.columns
        assert "é”€é‡" in cleaned_df.columns
        assert cleaned_df["é”€é‡"][0] == "7.5w~10w"
        
        # éªŒè¯_filteråˆ—åˆ›å»º
        assert "é”€é‡_filter" in cleaned_df.columns
        assert cleaned_df["é”€é‡_filter"][0] == 75000.0
```

#### 5.2 é›†æˆæµ‹è¯•
```python
def test_complete_workflow():
    """ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•"""
    # 1. æ–‡ä»¶ä¸Šä¼ æ¨¡æ‹Ÿ
    test_file_path = "data/test_sample.csv"
    
    # 2. å®Œæ•´å¤„ç†æµç¨‹
    result_df = process_douyin_export(test_file_path)
    
    # 3. éªŒè¯ç»“æœ
    assert result_df is not None
    assert len(result_df) > 0
    
    # 4. éªŒè¯_filteråˆ—
    filter_cols = [col for col in result_df.columns if col.endswith('_filter')]
    assert len(filter_cols) > 0
    
    # 5. æ¨¡æ‹Ÿç­›é€‰æ“ä½œ
    filtered_df = result_df.filter(pl.col("é”€é‡_filter") > 50000)
    
    # 6. éªŒè¯è¾“å‡ºæ ¼å¼
    export_df = filtered_df.drop(filter_cols)
    assert "é”€é‡_filter" not in export_df.columns
```

### 6. éƒ¨ç½²é…ç½®

#### 6.1 Dockeré…ç½®
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    software-properties-common \
    git \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

# æš´éœ²ç«¯å£
EXPOSE 8502

# å¥åº·æ£€æŸ¥
HEALTHCHECK CMD curl --fail http://localhost:8502/_stcore/health

# å¯åŠ¨å‘½ä»¤
ENTRYPOINT ["streamlit", "run", "app/ui/streamlit_app.py", "--server.port=8502", "--server.address=0.0.0.0"]
```

#### 6.2 å¯åŠ¨è„šæœ¬
```bash
#!/bin/bash
# run_web.sh

echo "--- å‡†å¤‡å¯åŠ¨æ•°æ®ç‚¼é‡‘å·¥åŠ Web ç•Œé¢ ---"

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# ç¯å¢ƒå˜é‡è®¾ç½®
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
export STREAMLIT_SERVER_PORT=8502
export STREAMLIT_BROWSER_GATHER_USAGE_STATS=false

# æ¸…ç†æ—§è¿›ç¨‹
pkill -f "streamlit.*8502" 2>/dev/null || true

# åå°å¯åŠ¨
nohup streamlit run app/ui/streamlit_app.py \
    --server.port=8502 \
    --server.address=0.0.0.0 \
    --server.headless=true \
    --browser.gatherUsageStats=false \
    > streamlit.log 2>&1 &

PID=$!
echo "Streamlit è¿›ç¨‹ID: $PID"
echo "ğŸŒ è¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®: http://localhost:8502"
```

### 7. ç›‘æ§ä¸æ—¥å¿—

#### 7.1 æ—¥å¿—ç³»ç»Ÿ
```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# å…³é”®æ“ä½œæ—¥å¿—
logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶ç±»å‹: {file_type}")
logger.info(f"æˆåŠŸè§£æ {len(tables)} ä¸ªè¡¨æ ¼")
logger.warning(f"è·³è¿‡å­—æ®µ {field} çš„èŒƒå›´è§£æ")
logger.error(f"å¤„ç†å¤±è´¥: {error}")
```

#### 7.2 æ€§èƒ½ç›‘æ§
```python
import time
from functools import wraps

def monitor_performance(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        
        logger.info(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {end_time - start_time:.4f}ç§’")
        return result
    return wrapper

@monitor_performance
def process_douyin_export(file_path):
    # å¤„ç†é€»è¾‘
    pass
```

### 8. å®‰å…¨æ€§è€ƒè™‘

#### 8.1 æ–‡ä»¶ä¸Šä¼ å®‰å…¨
```python
ALLOWED_EXTENSIONS = {'.csv', '.xlsx', '.xls'}
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

def validate_file(uploaded_file):
    # æ–‡ä»¶æ‰©å±•åæ£€æŸ¥
    file_ext = os.path.splitext(uploaded_file.name)[1].lower()
    if file_ext not in ALLOWED_EXTENSIONS:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_ext}")
    
    # æ–‡ä»¶å¤§å°æ£€æŸ¥
    if len(uploaded_file.getvalue()) > MAX_FILE_SIZE:
        raise ValueError("æ–‡ä»¶è¿‡å¤§ï¼Œè¶…è¿‡50MBé™åˆ¶")
    
    # æ–‡ä»¶å†…å®¹æ£€æŸ¥
    if len(uploaded_file.getvalue()) == 0:
        raise ValueError("æ–‡ä»¶ä¸ºç©º")
```

#### 8.2 æ•°æ®éšç§ä¿æŠ¤
```python
# ä¸´æ—¶æ–‡ä»¶å®‰å…¨åˆ é™¤
import os
import tempfile

def secure_temp_file_processing(uploaded_file):
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.tmp') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
        
        # è®¾ç½®æ–‡ä»¶æƒé™
        os.chmod(tmp_file_path, 0o600)  # åªæœ‰æ‰€æœ‰è€…å¯è¯»å†™
        
        # å¤„ç†æ–‡ä»¶
        result = process_file(tmp_file_path)
        
        return result
        
    finally:
        # å®‰å…¨åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(tmp_file_path):
            # è¦†ç›–æ–‡ä»¶å†…å®¹
            with open(tmp_file_path, 'wb') as f:
                f.write(b'\x00' * os.path.getsize(tmp_file_path))
            os.remove(tmp_file_path)
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0.0  
**æœ€åæ›´æ–°**: 2025å¹´6æœˆ21æ—¥  
**ç»´æŠ¤è€…**: Claude Code + æŠ€æœ¯å›¢é˜Ÿ